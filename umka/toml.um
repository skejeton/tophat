/**
 * TOML parser and deserializer. Can be used outside of tophat.
 * 
 * NUL (\0) is the EOF character.
 *
 * Identifier tokens and strings tokens are the same
 * 
 * Identifier tokens are not handled in nextToken/nextTokenKind because
 * TOML allows identifiers to start with numbers, so you'll have to know when you wanna retrieve it explicitly.
 * 
 * TODO: Handle newlines as semicolons, not as space
 */

type (
	Parser = struct {
		pos: uint
		sourceLen: uint
		source: str

		data: map[str]interface{}
	}

	Token = struct {
		kind: int
		value: str
	}

	TomlResult* = struct {
		data: map[str]interface{}
	}

	Accessor* = []str
)

const (
	tokInvalid = 0
	tokEof = 1
	tokSemi = 2
	tokAssign = 3
	tokString = 4
	tokDot = 5

	errUnknown = 0
	errUnclosedString = 1
	errCount = 2
)

// [\n]
fn isSemi(c: char): bool {
	return c == '\n'
}

// [ \t]
fn isSpace(c: char): bool {
	return c == ' ' || c == '\t'
}

// [ \t\r\n]
fn isSkip(c: char): bool {
	return c == ' ' || c == '\t' || c == '\r' || c == '\n'
}

// [A-Za-z0-9_-]
fn isIdent(c: char): bool {
	return (c >= 'a' && c <= 'z') || (c >= 'A' && c <= 'Z') || (c >= '0' && c <= '9') || (c == '_') || (c == '-')
}

// FIXME: this function will choke on invalid input
fn escapeStr(string: str): str {
	pos := 0
	pos += 1 // skip "
	result := ""

	for pos < len(string) && string[pos] != "\"" {
		if string[pos] == '\\' {
			pos++
			if pos < len(string) {
				result += string[pos]
				pos++
			}
		} else {
			result += string[pos]
			pos++
		}
	}

	return result
}

fn (p: ^Parser) next() {
	if p.pos < p.sourceLen {
		p.pos += 1
	}
}

fn (p: ^Parser) get(): char {
	if p.pos >= p.sourceLen {
		return '\0'
	}
	return p.source[p.pos]
}

fn (p: ^Parser) skipBlank() {
	for isSkip(p.get()) {
		p.next()
	}
}

fn (p: ^Parser) expectToken(token: Token, toBeKind: int) {
	if token.kind != toBeKind {
		// TODO: Error handling
	}
}

fn (p: ^Parser) nextTokenString(): int {
	p.next() // Skip quote
	for p.get() != '\0' && p.get() != '"' {
		if p.get() == '\\' {
			p.next()
		}
		p.next()
	}

	// TODO: Put error into the parser
	// Unfinished string
	if p.get() == '\0' {
		return tokInvalid
	}

	p.next() // Skip quote
	return tokString
}

fn (p: ^Parser) nextTokenKind(): int {
	switch (p.get()) {
		case '"':
			return p.nextTokenString()
		case '=': 
			p.next() // skip '='
			return tokAssign
		case '.': 
			p.next() // skip '.'
			return tokDot
		case '\0': 
			return tokEof
		default:
			return tokInvalid
	}
	return tokInvalid
}

fn (p: ^Parser) nextIdent(): Token {
	p.skipBlank()
	start := p.pos
	tt := tokInvalid

	if isIdent(p.get()) {
		for isIdent(p.get()) {
			p.next()
		}
		tt = tokString
	} else {
		tt = p.nextTokenKind()
	}

	end := p.pos

	token := Token{kind: tt, value: slice(p.source, start, end)}
	p.expectToken(token, tokString)

	// TODO: Error handling if not string encountered
	return token
}

fn (p: ^Parser) nextToken(): Token {
	p.skipBlank()

	start := p.pos

	tt := p.nextTokenKind()

	end := p.pos

	return Token{kind: tt, value: slice(p.source, start, end)}
}

fn (p: ^Parser) peekToken(): Token {
	tempPos := p.pos

	token := p.nextToken()

	p.pos = tempPos

	return token
}

// Runs escape sequences, if it's a quote string
fn escapeStrToken(token: Token): str {
	if token.kind == tokString && token.value[0] == '"' {
		return escapeStr(token.value)
	}
	return token.value
}

fn (p: ^Parser) parseAccessor(): Accessor {
	accessor := Accessor{escapeStrToken(p.nextIdent())}

	for p.peekToken().kind == tokDot {
		p.nextToken() // Skip dot
		accessor = append(accessor, escapeStrToken(p.nextIdent()))
	}

	return accessor
}

fn (p: ^Parser) setAccessor(accessor: Accessor, value: interface{}) {
	var tree: map[str]interface{} = p.data
	var last: interface{} = null

	for i, key in accessor {
		if !validkey(tree, key) {
			if i == len(accessor)-1 {
				tree[key] = value
			} else {
				tree[key] = map[str]interface{}{}
				tree = map[str]interface{}(tree[key])
			}
		} else {
			tree = map[str]interface{}(tree[key])
		}
	}
}

fn (p: ^Parser) parseKeyValue() {
	accessor := p.parseAccessor()
	assign := p.nextToken()
	p.expectToken(assign, tokAssign)
	value := p.nextToken()
	p.expectToken(value, tokString)

	printf("Set `%s` `%s` `%s`\n", repr(assign), repr(accessor), repr(value))
	p.setAccessor(accessor, escapeStrToken(value))
}

fn parse*(source: str): TomlResult {
	p := Parser{source: source, sourceLen: len(source), data: map[str]interface{}{}}

	for p.get() != '\0' {
		p.parseKeyValue()
	}

	return TomlResult{p.data}
}