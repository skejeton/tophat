/**
 * TOML parser and deserializer. Can be used outside of tophat.
 * 
 * NUL (\0) is the EOF character.
 *
 * Identifier tokens and strings tokens are the same
 * 
 * Identifier tokens are not handled in nextToken/nextTokenKind because
 * TOML allows identifiers to start with numbers, so you'll have to know when you wanna retrieve it explicitly.
 */

type (
	Accessor = []str

	FileLoc* = struct {
		line: int
		column: int
		offset: int
	}
	
	Error* = struct {
		location: FileLoc
		code: int
	}	

	Parser = struct {
		location: FileLoc
		sourceLen: uint
		source: str

		section: Accessor

		errors: []Error
		data: map[str]interface{}
	}

	Token = struct {
		kind: int
		value: str
		location: FileLoc
	}

	TomlResult* = struct {
		errors: []Error
		data: map[str]interface{}
	}
)

fn errorAtToken(token: Token, code: int): Error {
	return Error{location: token.location, code: code}
}

fn errorAtParser(parser: ^Parser, code: int): Error {
	return Error{location: parser.location, code: code}
}

fn errorAtLocation(location: FileLoc, code: int): Error {
	return Error{location: location, code: code}
}

const (
	tokInvalid = 0
	tokEof = 1
	tokSemi = 2
	tokAssign = 3
	tokString = 4
	tokDot = 5
	tokLBrack = 6 // [
	tokRBrack = 7 // ]

	errUnknown* = 0
	errUnclosedString* = 1
	errUnexpectedToken* = 2
	errUnexpectedCharacter* = 3
	errExpectedKey* = 4
	errFieldReassigned* = 5
	errExpectedNewLine* = 6
	errCount* = 7
)

fn formatError*(error: ^Error, source: str): str {
	const errCodeStr = [errCount]str{
		"Unknown error",
		"Unclosed string",
		"Unexpected token",
		"Unexpected character",
		"Invalid token for key",
		"Field reassigned", 
		"Expected new line"}

	return sprintf("error(%d:%d): %s", error.location.line+1, error.location.column+1, errCodeStr[error.code])	
}


// [ \t\r\n]
fn isSkip(c: char): bool {
	return c == ' ' || c == '\t' || c == '\r'
}

// [A-Za-z0-9_-]
fn isIdent(c: char): bool {
	return (c >= 'a' && c <= 'z') || (c >= 'A' && c <= 'Z') || (c >= '0' && c <= '9') || (c == '_') || (c == '-')
}

// FIXME: this function will choke on invalid input
fn escapeStr(string: str): str {
	pos := 0
	pos += 1 // skip "
	result := ""

	for pos < len(string) && string[pos] != "\"" {
		if string[pos] == '\\' {
			pos++
			if pos < len(string) {
				result += string[pos]
				pos++
			}
		} else {
			result += string[pos]
			pos++
		}
	}

	return result
}

fn (p: ^Parser) emitError(error: Error) {
	p.errors = append(p.errors, error)
}

fn (p: ^Parser) next() {
	if p.location.offset < p.sourceLen {
		if p.source[p.location.offset] == '\n' {
			p.location.line += 1
			p.location.column = 0
		} else {
			p.location.column += 1
		}
		p.location.offset += 1
	}
}

fn (p: ^Parser) get(): char {
	if p.location.offset >= p.sourceLen {
		return '\0'
	}
	return p.source[p.location.offset]
}

fn (p: ^Parser) skipBlank() {
	for isSkip(p.get()) {
		p.next()
	}
}

fn (p: ^Parser) expectToken(token: Token, toBeKind: int) {
	if token.kind != toBeKind {
		p.emitError(errorAtToken(token, errUnexpectedToken))
	}
}

fn (p: ^Parser) nextTokenString(): int {
	location := p.location

	p.next() // Skip quote
	for p.get() != '\0' && p.get() != '\n' && p.get() != '"' {
		if p.get() == '\\' {
			p.next()
		}
		p.next()
	}

	// Unfinished string
	if p.get() == '\0' || p.get() == '\n' {
		p.emitError(errorAtLocation(location, errUnclosedString))
		return tokInvalid
	}

	p.next() // Skip quote
	return tokString
}

fn (p: ^Parser) nextTokenKind(): int {
	switch (p.get()) {
		case '"':
			return p.nextTokenString()
		case '=': 
			p.next() // skip '='
			return tokAssign
		case '.': 
			p.next() // skip '.'
			return tokDot
		case '[': 
			p.next() // skip '['
			return tokLBrack
		case ']': 
			p.next() // skip ']'
			return tokRBrack
		case '\n': 
			p.next() // skip '\n'
			return tokSemi
		case '\0': 
			return tokEof
		default:
			// HACK eh? Toml has a semi context dependent thing where you need to know when to pull a key and when to pull 
			//	  			a number, because both numbers and keys can start with digits (and dash)...
			//					I'll better figure it out. 
			if !isIdent(p.get()) {
				p.emitError(errorAtParser(p, errUnexpectedCharacter))
			}
			return tokInvalid
	}
	return tokInvalid
}

fn (p: ^Parser) nextIdent(): Token {
	p.skipBlank()
	location := p.location
	start := p.location.offset
	tt := tokInvalid

	if isIdent(p.get()) {
		for isIdent(p.get()) {
			p.next()
		}
		tt = tokString
	} else {
		tt = p.nextTokenKind()
	}

	end := p.location.offset

	token := Token{kind: tt, value: slice(p.source, start, end), location: location}

	if tt != tokString {
		p.emitError(errorAtToken(token, errExpectedKey))
	}

	return token
}

fn (p: ^Parser) nextToken(): Token {
	p.skipBlank()

	location := p.location
	start := p.location.offset

	tt := p.nextTokenKind()

	end  := p.location.offset

	return Token{kind: tt, value: slice(p.source, start, end), location: location}
}

fn (p: ^Parser) peekToken(): Token {
	tempLoc := p.location

	token := p.nextToken()

	p.location = tempLoc

	return token
}

// Runs escape sequences, if it's a quote string
fn escapeStrToken(token: Token): str {
	if token.kind == tokString && token.value[0] == '"' {
		return escapeStr(token.value)
	}
	return token.value
}

fn (p: ^Parser) parseAccessor(): Accessor {
	accessor := Accessor{escapeStrToken(p.nextIdent())}

	for p.peekToken().kind == tokDot {
		p.nextToken() // Skip dot
		accessor = append(accessor, escapeStrToken(p.nextIdent()))
	}

	return accessor
}

fn (p: ^Parser) setAccessor(location: FileLoc, accessor: Accessor, value: interface{}) {
	var tree: map[str]interface{} = p.data

	for i, key in accessor {
		if i == len(accessor)-1 {
			if !valid(tree[key]) {
				tree[key] = value
			} else {
				p.emitError(errorAtLocation(location, errFieldReassigned))
			}
		} else {
			if !validkey(tree, key) {
				tree[key] = map[str]interface{}{}
				tree = map[str]interface{}(tree[key])
			} else {
				tree = map[str]interface{}(tree[key])
			}
		}
	}
}

fn (p: ^Parser) parseKeyValue() {
	location := p.location
	accessor := p.parseAccessor()

	assign := p.nextToken()
	p.expectToken(assign, tokAssign)
	value := p.nextToken()
	p.expectToken(value, tokString)

	printf("Set `%s` `%s` `%s`\n", repr(assign), repr(accessor), repr(value))
	p.setAccessor(location, append(p.section, accessor), escapeStrToken(value))
}

fn (p: ^Parser) parseSection() {
	p.expectToken(p.nextToken(), tokLBrack)
	p.section = p.parseAccessor()
	p.expectToken(p.nextToken(), tokRBrack)
}

fn (p: ^Parser) expectSemi() {
	token := p.nextToken()
	if !(token.kind == tokSemi || token.kind == tokEof) {
		p.emitError(errorAtToken(token, errExpectedNewLine))
	}
}

fn (p: ^Parser) parseToplevel() {
	switch p.peekToken().kind {
		// NOTE: Skip until the end of source, since peek doesn't move to the end of file while we skip spaces
		case tokEof: p.nextToken() 
		case tokSemi: p.nextToken()

		case tokLBrack: 
			p.parseSection()
			p.expectSemi()
		default:
			p.parseKeyValue() 
			p.expectSemi()
	}
}

fn parse*(source: str): TomlResult {
	p := Parser{source: source, section: []str{}, sourceLen: len(source), errors: []Error{}, data: map[str]interface{}{}}

	for len(p.errors) == 0 && p.peekToken().kind != tokEof {
		p.parseToplevel()
	}

	return TomlResult{p.errors, p.data}
}

fn (r: ^TomlResult) getError*(): ^Error {
	if len(r.errors) > 0 {
		return &r.errors[0]
	}
	return null
}
